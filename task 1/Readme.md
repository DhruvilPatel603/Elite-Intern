# Task 1 - Data Pipeline Development

## Overview
This project automates an ETL (Extract, Transform, Load) process using Python libraries like pandas and scikit-learn. It loads a sample dataset, cleans it, scales the features, and splits the data into training and testing sets.

## Technologies Used
- Python
- Pandas
- Scikit-learn

## Steps Performed
1. Loaded the Iris dataset.
2. Dropped missing values.
3. Scaled features using `StandardScaler`.
4. Split data into training and testing sets.
5. Saved processed files.

## Output
- `X_train.csv`
- `X_test.csv`
- `y_train.csv`
- `y_test.csv`

## How to Run
```bash
python data_pipeline.py
